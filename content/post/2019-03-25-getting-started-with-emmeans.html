---
title: Getting started with emmeans
author: Ariel Muldoon
date: '2019-03-25'
slug: getting-started-with-emmeans
categories:
  - r
  - statistics
tags:
  - analysis
  - teaching
  - emmeans
draft: FALSE
description: "Post hoc comparisons are made easy in package emmeans.  This post goes through some of the basics for those just getting started with the package."
---



<p>Package <strong>emmeans</strong> (formerly known as <strong>lsmeans</strong>) is enormously useful for folks wanting to do post hoc comparisons among groups after fitting a model. It has a very thorough set of vignettes (see the vignette topics <a href="https://cran.r-project.org/web/packages/emmeans/vignettes/basics.html#more">here</a>), is very flexible with a ton of options, and works out of the box with a lot of different model objects (and can be extended to others üëç).</p>
<p>I‚Äôve started recommending <strong>emmeans</strong> all the time to students fitting models in R. However, I‚Äôve found that often times students struggle a bit to get started using the package, possibly due to the sheer amount of flexibility and information in the vignettes.</p>
<p>I‚Äôve put together some basic examples for using <strong>emmeans</strong>, meant to be a complement to the vignettes. Specifically this post will demonstrate a few of the built-in options for some standard post hoc comparisons; I will write a separate post about custom comparisons in <strong>emmeans</strong>.</p>
<p><em>Disclaimer: This post is about using a package in R and so unfortunately does not focus on appropriate statistical practice for model fitting and post hoc comparisons.</em></p>
<div id="table-of-contents" class="section level2">
<h2>Table of Contents</h2>
<ul>
<li><a href="#r-packages">R packages</a></li>
<li><a href="#the-dataset-and-model">The dataset and model</a></li>
<li><a href="#built-in-comparisons-with-emmeans">Built in comparisons with emmeans()</a></li>
<li><a href="#all-pairwise-comparisons">All pairwise comparisons</a></li>
<li><a href="#back-transforming-results">Back-transforming results</a></li>
<li><a href="#changing-the-multiple-comparisons-adjustment">Changing the multiple comparisons adjustment</a></li>
<li><a href="#confidence-intervals-for-comparisons">Confidence intervals for comparisons</a></li>
<li><a href="#putting-results-in-a-data.frame">Putting results in a data.frame</a></li>
<li><a href="#within-group-comparisons">Within group comparisons</a></li>
<li><a href="#main-effects-comparisons">Main effects comparisons</a></li>
<li><a href="#treatment-vs-control-example">Treatment vs control example</a></li>
<li><a href="#alternative-code-for-comparisons">Alternative code for comparisons</a></li>
<li><a href="#just-the-code-please">Just the code, please</a></li>
</ul>
</div>
<div id="r-packages" class="section level1">
<h1>R packages</h1>
<p>I will load <strong>magrittr</strong> for the pipe in addition to <strong>emmeans</strong>.</p>
<pre class="r"><code>library(emmeans) # v. 1.3.3
library(magrittr) # v. 1.5</code></pre>
</div>
<div id="the-dataset-and-model" class="section level1">
<h1>The dataset and model</h1>
<p>I‚Äôve made a small dataset to use in this example. The response variable is <code>resp</code>, which comes from the log-normal distribution, and the two crossed factors of interest are <code>f1</code> and <code>f2</code>. Each factor has two levels: a control called <code>c</code> as well as a second non-control level.</p>
<pre class="r"><code>dat = structure(list(f1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c(&quot;a&quot;, 
&quot;c&quot;), class = &quot;factor&quot;), f2 = structure(c(1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c(&quot;1&quot;, 
&quot;c&quot;), class = &quot;factor&quot;), resp = c(1.6, 0.3, 3, 0.1, 3.2, 0.2, 
0.4, 0.4, 2.8, 0.7, 3.8, 3, 0.3, 14.3, 1.2, 0.5, 1.1, 4.4, 0.4, 
8.4)), row.names = c(NA, -20L), class = &quot;data.frame&quot;)

str(dat)</code></pre>
<pre><code># &#39;data.frame&#39;: 20 obs. of  3 variables:
#  $ f1  : Factor w/ 2 levels &quot;a&quot;,&quot;c&quot;: 1 1 1 1 1 1 1 1 1 1 ...
#  $ f2  : Factor w/ 2 levels &quot;1&quot;,&quot;c&quot;: 1 2 1 2 1 2 1 2 1 2 ...
#  $ resp: num  1.6 0.3 3 0.1 3.2 0.2 0.4 0.4 2.8 0.7 ...</code></pre>
<p>The model I will use is a linear model with a log-transformed response and the two factors and their interaction as explanatory variables. This is the ‚Äútrue‚Äù model since I created these data so I‚Äôm skipping all model checks here (which I would not do in a real analysis).</p>
<p>Note I use <code>log(resp)</code> in the model rather than creating a new log-transformed variable. This will allow me to demonstrate one of the convenient options available in <code>emmeans()</code> later.</p>
<pre class="r"><code>fit1 = lm(log(resp) ~ f1 + f2 + f1:f2, data = dat)</code></pre>
</div>
<div id="built-in-comparisons-with-emmeans" class="section level1">
<h1>Built in comparisons with emmeans()</h1>
<p>The <strong>emmeans</strong> package has helper functions for commonly used post hoc comparisons (aka <em>contrasts</em>). For example, we can do pairwise comparisons via <code>pairwise</code> or <code>revpairwise</code>, treatment vs control comparisons via <code>trt.vs.ctrl</code> or <code>trt.vs.ctrlk</code>, and even consecutive comparisons via <code>consec</code>.</p>
<p>The available built-in functions for doing comparisons are listed in the documentation for <code>?"contrast-methods"</code>.</p>
</div>
<div id="all-pairwise-comparisons" class="section level1">
<h1>All pairwise comparisons</h1>
<p>One way to use <code>emmeans()</code>, which I use a lot, is to use formula coding for the comparisons. This formula is defined in the <code>specs</code> argument.</p>
<p>I will do all pairwise comparisons for all combinations of <code>f1</code> and <code>f2</code>. The built-in function <code>pairwise</code> is put on the left-hand side of the formula in <code>specs</code> and the factors with levels we want to compare among are on the right-hand side. Since I‚Äôm doing all pairwise comparisons, the combination of <code>f1</code> and <code>f2</code> are put in the formula.</p>
<p>The model object is passed to the first argument in <code>emmeans()</code>, <code>object</code>.</p>
<pre class="r"><code>emm1 = emmeans(fit1, specs = pairwise ~ f1:f2)</code></pre>
<p>Using the formula in this way returns an object with two parts. The first part, called <code>emmeans</code>, is the estimated marginal means along with the standard errors and confidence intervals. We can pull these out with dollar sign notation, which I do below.</p>
<p>These results are all on the <em>model</em> scale, so in this case these are estimated mean log response for each <code>f1</code> and <code>f2</code> combination. Note the message that <code>emmeans()</code> gives us about results being on the log scale in the output. It knows the model is on the log scale because I used <code>log(resp)</code> as my response variable.</p>
<pre class="r"><code>emm1$emmeans</code></pre>
<pre><code>#  f1 f2 emmean    SE df lower.CL upper.CL
#  a  1   0.569 0.445 16   -0.374    1.512
#  c  1  -0.102 0.445 16   -1.045    0.842
#  a  c  -1.278 0.445 16   -2.221   -0.334
#  c  c   1.335 0.445 16    0.392    2.279
# 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95</code></pre>
<p>The second part of the output, called <code>contrasts</code>, contains the comparisons of interest. It is this section that we are generally most interested in when answering a question about differences among groups.</p>
<p>These results are also on the model scale (and we get the same message in this section), and <a href="#back-transforming-results">we‚Äôll want to put them on the original scale</a>.</p>
<p>The comparisons are accompanied by statistical tests of the null hypothesis of ‚Äúno difference‚Äù, but lack confidence interval (CI) limits by default. <a href="#confidence-intervals-for-comparisons">We‚Äôll need to get these</a>.</p>
<p>The <code>emmeans()</code> package automatically adjusts for multiple comparisons. Since we did all pairwise comparisons the package used a Tukey adjustment. <a href="#changing-the-multiple-comparisons-adjustment">The type of adjustment can be changed</a>.</p>
<pre class="r"><code>emm1$contrasts</code></pre>
<pre><code>#  contrast  estimate    SE df t.ratio p.value
#  a,1 - c,1    0.671 0.629 16  1.065  0.7146 
#  a,1 - a,c    1.847 0.629 16  2.934  0.0434 
#  a,1 - c,c   -0.766 0.629 16 -1.217  0.6253 
#  c,1 - a,c    1.176 0.629 16  1.869  0.2795 
#  c,1 - c,c   -1.437 0.629 16 -2.283  0.1438 
#  a,c - c,c   -2.613 0.629 16 -4.152  0.0038 
# 
# Results are given on the log (not the response) scale. 
# P value adjustment: tukey method for comparing a family of 4 estimates</code></pre>
</div>
<div id="back-transforming-results" class="section level1">
<h1>Back-transforming results</h1>
<p>Since I used a log transformation I can express the results as multiplicative differences in medians on the original (data) scale. We can always back-transform estimates and CI limits by hand, but in <code>emmeans()</code> we can use the <code>type</code> argument for this. Using <code>type = "response"</code> will return results on the original scale. This works when the transformation is explicit in the model (e.g., <code>log(resp)</code>) and works similarly for link functions in generalized linear models.</p>
<p>You‚Äôll see the message changes in the output once I do this, indicating things were back-transformed from the model scale. We also are reminded that the tests were done on the model scale.</p>
<p>In the <code>contrast</code> column in the <code>contrasts</code> section we can see the expression of the comparisons has changed from additive comparisons (via subtraction) shown above to multiplicative comparisons (via division).</p>
<pre class="r"><code>emmeans(fit1, specs = pairwise ~ f1:f2, type = &quot;response&quot;)</code></pre>
<pre><code># $emmeans
#  f1 f2 response    SE df lower.CL upper.CL
#  a  1     1.767 0.786 16    0.688    4.538
#  c  1     0.903 0.402 16    0.352    2.321
#  a  c     0.279 0.124 16    0.108    0.716
#  c  c     3.800 1.691 16    1.479    9.763
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale 
# 
# $contrasts
#  contrast   ratio     SE df t.ratio p.value
#  a,1 / c,1 1.9553 1.2306 16  1.065  0.7146 
#  a,1 / a,c 6.3396 3.9900 16  2.934  0.0434 
#  a,1 / c,c 0.4648 0.2926 16 -1.217  0.6253 
#  c,1 / a,c 3.2422 2.0406 16  1.869  0.2795 
#  c,1 / c,c 0.2377 0.1496 16 -2.283  0.1438 
#  a,c / c,c 0.0733 0.0461 16 -4.152  0.0038 
# 
# P value adjustment: tukey method for comparing a family of 4 estimates 
# Tests are performed on the log scale</code></pre>
</div>
<div id="changing-the-multiple-comparisons-adjustment" class="section level1">
<h1>Changing the multiple comparisons adjustment</h1>
<p>The <code>adjust</code> argument can be used to change the type of multiple comparisons adjustment. All available options are listed and described in the documentation for <code>summary.emmGrid</code> under the section <em>P-value adjustments</em>.</p>
<p>One option is to skip multiple comparisons adjustments all together, using <code>adjust = "none"</code>. If we use this the message about multiple comparisons disappears (since we didn‚Äôt use one).</p>
<pre class="r"><code>emm1.1 = emmeans(fit1, specs = pairwise ~ f1:f2, type = &quot;response&quot;, adjust = &quot;none&quot;)
emm1.1</code></pre>
<pre><code># $emmeans
#  f1 f2 response    SE df lower.CL upper.CL
#  a  1     1.767 0.786 16    0.688    4.538
#  c  1     0.903 0.402 16    0.352    2.321
#  a  c     0.279 0.124 16    0.108    0.716
#  c  c     3.800 1.691 16    1.479    9.763
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale 
# 
# $contrasts
#  contrast   ratio     SE df t.ratio p.value
#  a,1 / c,1 1.9553 1.2306 16  1.065  0.3025 
#  a,1 / a,c 6.3396 3.9900 16  2.934  0.0097 
#  a,1 / c,c 0.4648 0.2926 16 -1.217  0.2412 
#  c,1 / a,c 3.2422 2.0406 16  1.869  0.0801 
#  c,1 / c,c 0.2377 0.1496 16 -2.283  0.0365 
#  a,c / c,c 0.0733 0.0461 16 -4.152  0.0008 
# 
# Tests are performed on the log scale</code></pre>
</div>
<div id="confidence-intervals-for-comparisons" class="section level1">
<h1>Confidence intervals for comparisons</h1>
<p>We will almost invariably want to report confidence intervals for any comparisons of interest. We need a separate function to get these. Here is an example using the <code>confint()</code> function with the default 95% CI (the confidence level can be changed, see <code>?confint.emmGrid</code>). I use the pipe to pass the <code>contrasts</code> into the <code>confint()</code> function.</p>
<pre class="r"><code>emm1.1$contrasts %&gt;%
     confint()</code></pre>
<pre><code>#  contrast   ratio     SE df lower.CL upper.CL
#  a,1 / c,1 1.9553 1.2306 16   0.5150    7.424
#  a,1 / a,c 6.3396 3.9900 16   1.6696   24.072
#  a,1 / c,c 0.4648 0.2926 16   0.1224    1.765
#  c,1 / a,c 3.2422 2.0406 16   0.8539   12.311
#  c,1 / c,c 0.2377 0.1496 16   0.0626    0.903
#  a,c / c,c 0.0733 0.0461 16   0.0193    0.278
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale</code></pre>
<p>The <code>confint()</code> function returns confidence intervals but gets rid of the statistical tests. Some people will want to also report the test statistics and p-values. In this case, we can use <code>summary()</code> instead of <code>confint()</code>, with <code>infer = TRUE</code>.</p>
<pre class="r"><code>emm1.1$contrasts %&gt;%
     summary(infer = TRUE)</code></pre>
<pre><code>#  contrast   ratio     SE df lower.CL upper.CL t.ratio p.value
#  a,1 / c,1 1.9553 1.2306 16   0.5150    7.424  1.065  0.3025 
#  a,1 / a,c 6.3396 3.9900 16   1.6696   24.072  2.934  0.0097 
#  a,1 / c,c 0.4648 0.2926 16   0.1224    1.765 -1.217  0.2412 
#  c,1 / a,c 3.2422 2.0406 16   0.8539   12.311  1.869  0.0801 
#  c,1 / c,c 0.2377 0.1496 16   0.0626    0.903 -2.283  0.0365 
#  a,c / c,c 0.0733 0.0461 16   0.0193    0.278 -4.152  0.0008 
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale 
# Tests are performed on the log scale</code></pre>
</div>
<div id="putting-results-in-a-data.frame" class="section level1">
<h1>Putting results in a data.frame</h1>
<p>One of the really nice things about <code>emmeans()</code> is that it makes it easy to get the results into a nice format for making tables or graphics of results. This is because the results can be converted into a data.frame via <code>as.data.frame()</code>.</p>
<p>This is true for both <code>confint()</code> and <code>summary()</code>, although I‚Äôll just show <code>confint()</code> here. After getting the confidence intervals I pipe the results into <code>as.data.frame()</code>. I assign this object a name so I can use it for, e.g., making a graph of results.</p>
<pre class="r"><code>emm1.1_contrasts = emm1.1$contrasts %&gt;%
     confint() %&gt;%
     as.data.frame()

emm1.1_contrasts</code></pre>
<pre><code>#    contrast      ratio         SE df   lower.CL   upper.CL
# 1 a,1 / c,1 1.95530312 1.23062914 16 0.51495216  7.4243989
# 2 a,1 / a,c 6.33957277 3.99000180 16 1.66960135 24.0717240
# 3 a,1 / c,c 0.46482555 0.29255202 16 0.12241730  1.7649695
# 4 c,1 / a,c 3.24224552 2.04060525 16 0.85388364 12.3109935
# 5 c,1 / c,c 0.23772557 0.14961978 16 0.06260784  0.9026577
# 6 a,c / c,c 0.07332127 0.04614696 16 0.01931002  0.2784051</code></pre>
<p>If needed, the estimated marginal means can also be put into a data.frame.</p>
<pre class="r"><code>emm1.1$emmeans %&gt;%
     as.data.frame()</code></pre>
<pre><code>#   f1 f2  response        SE df  lower.CL upper.CL
# 1  a  1 1.7665334 0.7861763 16 0.6876870 4.537879
# 2  c  1 0.9034576 0.4020739 16 0.3517035 2.320806
# 3  a  c 0.2786518 0.1240109 16 0.1084753 0.715802
# 4  c  c 3.8004222 1.6913362 16 1.4794517 9.762542</code></pre>
</div>
<div id="within-group-comparisons" class="section level1">
<h1>Within group comparisons</h1>
<p>While we <em>can</em> do all pairwise comparisons, there are certainly plenty of situations where the research question dictates that we only want a specific set of comparisons. A common example of this is when we want to compare the levels of one factor within the levels of another. Here I‚Äôll show comparisons among levels of <code>f1</code> for each level of <code>f2</code>.</p>
<p>The only thing that changes is the right-hand side of the <code>specs</code> formula. The code <code>f1|f2</code> translates to ‚Äúcompare levels of <code>f1</code> within each level of <code>f2</code>‚Äù.</p>
<pre class="r"><code>emm2 = emmeans(fit1, specs = pairwise ~ f1|f2, type = &quot;response&quot;)
emm2</code></pre>
<pre><code># $emmeans
# f2 = 1:
#  f1 response    SE df lower.CL upper.CL
#  a     1.767 0.786 16    0.688    4.538
#  c     0.903 0.402 16    0.352    2.321
# 
# f2 = c:
#  f1 response    SE df lower.CL upper.CL
#  a     0.279 0.124 16    0.108    0.716
#  c     3.800 1.691 16    1.479    9.763
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale 
# 
# $contrasts
# f2 = 1:
#  contrast  ratio     SE df t.ratio p.value
#  a / c    1.9553 1.2306 16  1.065  0.3025 
# 
# f2 = c:
#  contrast  ratio     SE df t.ratio p.value
#  a / c    0.0733 0.0461 16 -4.152  0.0008 
# 
# Tests are performed on the log scale</code></pre>
<p>You can see there is no message about a multiple comparisons adjustment in the above set of comparisons. This is because the package default is to correct for the number of comparisons <em>within</em> each group instead of across groups. In this case there is only a single comparison in each group.</p>
<p>If we consider the family of comparisons to be all comparisons regardless of group and want to correct for multiple comparisons, we can do so via <code>rbind.emmGrid</code>.</p>
<p>Here is an example of passing <code>contrasts</code> to <code>rbind()</code> to correct for multiple comparisons. The default adjustment is Bonferroni, which can be much too conservative when the number of comparisons is large. You can control the multiple comparisons procedure via <code>adjust</code>.</p>
<p>The results of <code>rbind()</code> can also be used with <code>summary()</code>, <code>confint()</code>, and/or <code>as.data.frame()</code>.</p>
<pre class="r"><code>emm2$contrasts %&gt;%
     rbind()</code></pre>
<pre><code>#  f2 contrast  ratio     SE df t.ratio p.value
#  1  a / c    1.9553 1.2306 16  1.065  0.6050 
#  c  a / c    0.0733 0.0461 16 -4.152  0.0015 
# 
# P value adjustment: bonferroni method for 2 tests 
# Tests are performed on the log scale</code></pre>
</div>
<div id="main-effects-comparisons" class="section level1">
<h1>Main effects comparisons</h1>
<p>Even if we have multiple factors in the model, complete with an interaction term, we can still do ‚Äúoverall‚Äù comparisons among groups if our research question indicated that main effects were an important thing to estimate.</p>
<p>Doing main effects in the presence of an interaction means we <em>average over</em> the levels of the other factor(s). The <code>emmeans()</code> function gives both a warning about the interaction and a message indicating which factor was averaged over to remind us of this.</p>
<p>Here is the estimated main effect of <code>f1</code>. Since we are only interested in overall comparisons of that factor it is the only factor given on the right-hand side of the <code>specs</code> formula.</p>
<pre class="r"><code>emmeans(fit1, specs = pairwise ~ f1)</code></pre>
<pre><code># NOTE: Results may be misleading due to involvement in interactions</code></pre>
<pre><code># $emmeans
#  f1 emmean    SE df lower.CL upper.CL
#  a  -0.354 0.315 16  -1.0215    0.313
#  c   0.617 0.315 16  -0.0503    1.284
# 
# Results are averaged over the levels of: f2 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95 
# 
# $contrasts
#  contrast estimate    SE df t.ratio p.value
#  a - c      -0.971 0.445 16 -2.182  0.0443 
# 
# Results are averaged over the levels of: f2 
# Results are given on the log (not the response) scale.</code></pre>
</div>
<div id="treatment-vs-control-example" class="section level1">
<h1>Treatment vs control example</h1>
<p>The <strong>emmeans</strong> package has built-in helper functions for comparing each group mean to the control mean. If the control group is the in the first row of the <code>emmeans</code> section of the output, this set of comparisons can be requested via <code>trt.vs.ctrl</code>.</p>
<p>Note the default multiple comparisons adjustment is a Dunnett adjustment.</p>
<pre class="r"><code>emmeans(fit1, specs = trt.vs.ctrl ~ f1:f2)</code></pre>
<pre><code># $emmeans
#  f1 f2 emmean    SE df lower.CL upper.CL
#  a  1   0.569 0.445 16   -0.374    1.512
#  c  1  -0.102 0.445 16   -1.045    0.842
#  a  c  -1.278 0.445 16   -2.221   -0.334
#  c  c   1.335 0.445 16    0.392    2.279
# 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95 
# 
# $contrasts
#  contrast  estimate    SE df t.ratio p.value
#  c,1 - a,1   -0.671 0.629 16 -1.065  0.5857 
#  a,c - a,1   -1.847 0.629 16 -2.934  0.0262 
#  c,c - a,1    0.766 0.629 16  1.217  0.4947 
# 
# Results are given on the log (not the response) scale. 
# P value adjustment: dunnettx method for 3 tests</code></pre>
<p>Using <code>trt.vs.ctrl</code> means we ended up comparing each group mean to the ‚Äúa 1‚Äù group since it is in the first row. In the example I‚Äôm using the control group, ‚Äúc c‚Äù, is actually the <em>last</em> group listed in the <code>emmeans</code> section. When the control group is the last group in <code>emmeans</code> we can use <code>trt.vs.ctrlk</code> to get the correct set of comparisons.</p>
<pre class="r"><code>emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2)</code></pre>
<pre><code># $emmeans
#  f1 f2 emmean    SE df lower.CL upper.CL
#  a  1   0.569 0.445 16   -0.374    1.512
#  c  1  -0.102 0.445 16   -1.045    0.842
#  a  c  -1.278 0.445 16   -2.221   -0.334
#  c  c   1.335 0.445 16    0.392    2.279
# 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95 
# 
# $contrasts
#  contrast  estimate    SE df t.ratio p.value
#  a,1 - c,c   -0.766 0.629 16 -1.217  0.4947 
#  c,1 - c,c   -1.437 0.629 16 -2.283  0.0935 
#  a,c - c,c   -2.613 0.629 16 -4.152  0.0021 
# 
# Results are given on the log (not the response) scale. 
# P value adjustment: dunnettx method for 3 tests</code></pre>
<p>That gives us what we want in this case. However, if the control group was some other group, like ‚Äúc 1‚Äù, we could use <code>trt.vs.ctrlk</code> with the <code>ref</code> argument to define which row in the <code>emmeans</code> section represents the control group.</p>
<p>The ‚Äúc 1‚Äù group is the second row in the <code>emmeans</code> so we can use <code>ref = 2</code> to define this group as the control group.</p>
<pre class="r"><code>emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2, ref = 2)</code></pre>
<pre><code># $emmeans
#  f1 f2 emmean    SE df lower.CL upper.CL
#  a  1   0.569 0.445 16   -0.374    1.512
#  c  1  -0.102 0.445 16   -1.045    0.842
#  a  c  -1.278 0.445 16   -2.221   -0.334
#  c  c   1.335 0.445 16    0.392    2.279
# 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95 
# 
# $contrasts
#  contrast  estimate    SE df t.ratio p.value
#  a,1 - c,1    0.671 0.629 16  1.065  0.5857 
#  a,c - c,1   -1.176 0.629 16 -1.869  0.1937 
#  c,c - c,1    1.437 0.629 16  2.283  0.0935 
# 
# Results are given on the log (not the response) scale. 
# P value adjustment: dunnettx method for 3 tests</code></pre>
<p>Finally, if we want to reverse the order of subtraction in the treatment vs control comparisons we can use the <code>reverse</code> argument.</p>
<pre class="r"><code>emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2, ref = 2, reverse = TRUE)</code></pre>
<pre><code># $emmeans
#  f1 f2 emmean    SE df lower.CL upper.CL
#  a  1   0.569 0.445 16   -0.374    1.512
#  c  1  -0.102 0.445 16   -1.045    0.842
#  a  c  -1.278 0.445 16   -2.221   -0.334
#  c  c   1.335 0.445 16    0.392    2.279
# 
# Results are given on the log (not the response) scale. 
# Confidence level used: 0.95 
# 
# $contrasts
#  contrast  estimate    SE df t.ratio p.value
#  c,1 - a,1   -0.671 0.629 16 -1.065  0.5857 
#  c,1 - a,c    1.176 0.629 16  1.869  0.1937 
#  c,1 - c,c   -1.437 0.629 16 -2.283  0.0935 
# 
# Results are given on the log (not the response) scale. 
# P value adjustment: dunnettx method for 3 tests</code></pre>
</div>
<div id="alternative-code-for-comparisons" class="section level1">
<h1>Alternative code for comparisons</h1>
<p>The <code>emmeans()</code> package offers the option to do comparisons in two steps instead of in one step the way I have been using it as above. I personally find this alternative most useful when doing custom comparisons, and I think it‚Äôs good to introduce it now so it looks familiar. This alternative keeps the estimated marginal means and the comparisons of interest in separate objects, which may be attractive in some situations.</p>
<p>The first step is to use <code>emmeans()</code> to calculate the marginal means of interest. We still use the formula in <code>specs</code> with the factor(s) of interest on the right-hand side but no longer put anything on the left-hand side of the tilde.</p>
<p>We can still use <code>type</code> in <code>emmeans()</code> but cannot use <code>adjust</code> (since we don‚Äôt adjust for multiple comparisons until we‚Äôve actually done comparisons üòâ).</p>
<pre class="r"><code>emm3 = emmeans(fit1, specs = ~ f1:f2, type = &quot;response&quot;)
emm3</code></pre>
<pre><code>#  f1 f2 response    SE df lower.CL upper.CL
#  a  1     1.767 0.786 16    0.688    4.538
#  c  1     0.903 0.402 16    0.352    2.321
#  a  c     0.279 0.124 16    0.108    0.716
#  c  c     3.800 1.691 16    1.479    9.763
# 
# Confidence level used: 0.95 
# Intervals are back-transformed from the log scale</code></pre>
<p>We then get the comparisons we want in a second step using the <code>contrast()</code> function. We request the comparisons we want via <code>method</code>. When using built-in comparisons like I am here, we give the comparison function name as a string (meaning in quotes). Also see the <code>pairs()</code> function, which is for the special case of all pairwise comparisons.</p>
<p>We can use <code>adjust</code> in <code>contrast()</code> to change the multiple comparisons adjustment.</p>
<pre class="r"><code>contrast(emm3, method = &quot;pairwise&quot;, adjust = &quot;none&quot;)</code></pre>
<pre><code>#  contrast   ratio     SE df t.ratio p.value
#  a,1 / c,1 1.9553 1.2306 16  1.065  0.3025 
#  a,1 / a,c 6.3396 3.9900 16  2.934  0.0097 
#  a,1 / c,c 0.4648 0.2926 16 -1.217  0.2412 
#  c,1 / a,c 3.2422 2.0406 16  1.869  0.0801 
#  c,1 / c,c 0.2377 0.1496 16 -2.283  0.0365 
#  a,c / c,c 0.0733 0.0461 16 -4.152  0.0008 
# 
# Tests are performed on the log scale</code></pre>
<p>We can follow the <code>contrast()</code> argument with <code>summary()</code> or <code>confint()</code> and then put the results into a data.frame for plotting/saving. Again, I think the real strength of <code>contrast()</code> comes when we want custom comparisons, and I‚Äôll demonstrate these in my next post.</p>
</div>
<div id="just-the-code-please" class="section level1">
<h1>Just the code, please</h1>
<p>Here‚Äôs the code without all the discussion. Copy and paste the code below or you can download an R script of uncommented code <a href="/script/2019-03-25-getting-started-with-emmeans.R">from here</a>.</p>
<pre class="r"><code>library(emmeans) # v. 1.3.3
library(magrittr) # v. 1.5

dat = structure(list(f1 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c(&quot;a&quot;, 
&quot;c&quot;), class = &quot;factor&quot;), f2 = structure(c(1L, 2L, 1L, 2L, 1L, 
2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L, 1L, 2L), .Label = c(&quot;1&quot;, 
&quot;c&quot;), class = &quot;factor&quot;), resp = c(1.6, 0.3, 3, 0.1, 3.2, 0.2, 
0.4, 0.4, 2.8, 0.7, 3.8, 3, 0.3, 14.3, 1.2, 0.5, 1.1, 4.4, 0.4, 
8.4)), row.names = c(NA, -20L), class = &quot;data.frame&quot;)

str(dat)

fit1 = lm(log(resp) ~ f1 + f2 + f1:f2, data = dat)

emm1 = emmeans(fit1, specs = pairwise ~ f1:f2)

emm1$emmeans
emm1$contrasts

emmeans(fit1, specs = pairwise ~ f1:f2, type = &quot;response&quot;)

emm1.1 = emmeans(fit1, specs = pairwise ~ f1:f2, type = &quot;response&quot;, adjust = &quot;none&quot;)
emm1.1

emm1.1$contrasts %&gt;%
     confint()

emm1.1$contrasts %&gt;%
     summary(infer = TRUE)

emm1.1_contrasts = emm1.1$contrasts %&gt;%
     confint() %&gt;%
     as.data.frame()

emm1.1_contrasts

emm1.1$emmeans %&gt;%
     as.data.frame()

emm2 = emmeans(fit1, specs = pairwise ~ f1|f2, type = &quot;response&quot;)
emm2

emm2$contrasts %&gt;%
     rbind()

emmeans(fit1, specs = pairwise ~ f1)

emmeans(fit1, specs = trt.vs.ctrl ~ f1:f2)

emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2)

emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2, ref = 2)

emmeans(fit1, specs = trt.vs.ctrlk ~ f1:f2, ref = 2, reverse = TRUE)

emm3 = emmeans(fit1, specs = ~ f1:f2, type = &quot;response&quot;)
emm3

contrast(emm3, method = &quot;pairwise&quot;, adjust = &quot;none&quot;)</code></pre>
</div>
